{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import libraries\n",
    "\n",
    "import os, glob, pandas as pd\n",
    "import string, re\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import numbers\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import figure\n",
    "from string import ascii_lowercase\n",
    "import os \n",
    "import glob\n",
    "import re\n",
    "import requests\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import time\n",
    "from nltk import ngrams\n",
    "from operator import itemgetter\n",
    "import pickle\n",
    "from flashtext import KeywordProcessor\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C://Users//Ruben//Documents//Artikelen//Joris\")\n",
    "with open('stopwords-nl.txt', encoding = 'utf-8') as f:\n",
    "    stopz = f.read().splitlines()\n",
    "\n",
    "os.chdir(\"C://Users//Ruben//Documents//GitHub//dhl-ads//resources\")\n",
    "with open('occupations_dictionary.pkl', 'rb') as handle:\n",
    "    occ_dict = pickle.load(handle)\n",
    "    \n",
    "list_words = []\n",
    "for k,v in occ_dict.items():\n",
    "    k = k\n",
    "    v = [x for x in v if x not in stopz and len(x) > 3]\n",
    "    \n",
    "    for x in v:\n",
    "        list_words.append(x)\n",
    "    list_words.append(k)\n",
    "    \n",
    "keyword_processor = KeywordProcessor()\n",
    "for w in list_words:\n",
    "    keyword_processor.add_keyword(w)\n",
    "    \n",
    "os.chdir(\"C://Users//Ruben//Downloads//metadata//leco_set_80\")\n",
    "df = pd.read_csv('1880-1890.csv', sep = '\\t')\n",
    "\n",
    "def clean_and_split_str(txt):\n",
    "    #strip_special_chars = re.compile(\"[^A-Za-z0-9#]+\")\n",
    "    translator = str.maketrans('', '', string.punctuation)\n",
    "    txt = txt.translate(translator)\n",
    "    txt = re.sub('\\s+', ' ', txt).strip()\n",
    "    txt = txt.lower()\n",
    "    txt = txt.split(' ')\n",
    "    return txt\n",
    "\n",
    "df['clean'] = [clean_and_split_str(i) for i in df.ocr]\n",
    "\n",
    "# Import QUAL Indicator list\n",
    "os.chdir(\"C://Users//Ruben//Documents//GitHub//dhl-ads//resources\")\n",
    "with open('qualitative_indicators.txt', encoding = 'utf-8') as f:\n",
    "    qual_words = f.read().splitlines()\n",
    "    \n",
    "# Import QUAL Indicator list\n",
    "os.chdir(\"C://Users//Ruben//Documents//GitHub//dhl-ads//resources\")\n",
    "with open('wage_indicators.txt', encoding = 'utf-8') as f:\n",
    "    wage_words = f.read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ExtractWindows2(df, list_words, qual_words):\n",
    "    alphabet_id = [c for c in ascii_lowercase] + [c + c for c in ascii_lowercase] + [c + c +c for c in ascii_lowercase]\n",
    "\n",
    "    opd = dict()\n",
    "    ctr = 0 # counter for showing progress\n",
    "\n",
    "    for c,i in enumerate(df.clean):\n",
    "        ctr += 1\n",
    "        \n",
    "        extracted_occupations = keyword_processor.extract_keywords(\" \".join(i))\n",
    "        extracted_occupations = [o for o in extracted_occupations if o in i]\n",
    "        \n",
    "        if len(extracted_occupations) > 0:     # check if there is an occupation in the advertisement\n",
    "\n",
    "            for count,o in enumerate(extracted_occupations):                       # loop over occupations in ad-occupation list and select windows around 'em\n",
    "                ind = i.index(o)\n",
    "                sl = i[ind-12:ind+40]\n",
    "                sl = ' '.join(sl)\n",
    "                if 'loon ' in sl or 'salaris' in sl:               # if the word 'loon' is in the window; append [occupation:window] to list (not dictionary because of duplicate occupations)\n",
    "                    output_list = [o, sl, df['id'][c], df['date'][c], df['image_url'][c], i, ind]\n",
    "                    opd.update({str(c) + alphabet_id[count]:output_list})\n",
    "\n",
    "        if ctr % 5000 == 0:                    # print the progress\n",
    "            print(str(round(ctr / len(df.clean) * 100)) + \"%\")\n",
    "    \n",
    "    \n",
    "    ## Convert output dictionary to dataframe (for clarity)\n",
    "    dfa = pd.DataFrame([opd.keys() ,[v[3] for k,v in opd.items()], [v[0] for k,v in opd.items()], [v[1] for k,v in opd.items()],[v[4] for k,v in opd.items()], [' '.join(v[5]) for k,v in opd.items()],[v[6] for k,v in opd.items()],]).T\n",
    "    dfa.columns = ['id','date', 'oc', 'window','image_url', 'ocr', 'occ_index']\n",
    "    return dfa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5%\n",
      "11%\n",
      "16%\n",
      "22%\n",
      "27%\n",
      "32%\n",
      "38%\n",
      "43%\n",
      "48%\n",
      "54%\n",
      "59%\n",
      "65%\n",
      "70%\n",
      "75%\n",
      "81%\n",
      "86%\n",
      "91%\n",
      "97%\n"
     ]
    }
   ],
   "source": [
    "dfr = ExtractWindows2(df, list_words, qual_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"C://Users//Ruben//Downloads//metadata//ads_all_1870s\")\n",
    "df1 = pd.read_csv('1870-1872.csv', sep = '\\t')\n",
    "df2 = pd.read_csv('1872-1879.csv', sep = '\\t')\n",
    "df = df1.append(df2)\n",
    "\n",
    "df.to_csv('1870-1879.csv', sep = \"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [c for c in ascii_lowercase]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [''.join(i) for i in itertools.product(l, repeat = 4)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "456976"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
